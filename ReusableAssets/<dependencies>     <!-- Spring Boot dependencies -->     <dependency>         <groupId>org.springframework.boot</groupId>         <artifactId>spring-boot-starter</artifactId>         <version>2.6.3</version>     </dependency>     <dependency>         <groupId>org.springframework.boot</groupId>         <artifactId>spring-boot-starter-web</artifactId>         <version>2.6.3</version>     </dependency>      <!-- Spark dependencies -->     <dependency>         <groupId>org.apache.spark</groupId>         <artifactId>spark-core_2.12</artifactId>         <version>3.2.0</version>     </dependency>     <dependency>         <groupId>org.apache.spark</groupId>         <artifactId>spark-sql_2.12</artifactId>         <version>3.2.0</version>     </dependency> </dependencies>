<dependencies>
    <!-- Spring Boot dependencies -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter</artifactId>
        <version>2.6.3</version>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
        <version>2.6.3</version>
    </dependency>

    <!-- Spark dependencies -->
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-core_2.12</artifactId>
        <version>3.2.0</version>
    </dependency>
    <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-sql_2.12</artifactId>
        <version>3.2.0</version>
    </dependency>
</dependencies>



import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaSparkContext;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class MyApplication implements CommandLineRunner {

    public static void main(String[] args) {
        SpringApplication.run(MyApplication.class, args);
    }

    @Override
    public void run(String... args) throws Exception {
        // Create a Spark configuration
        SparkConf conf = new SparkConf()
                .setAppName("My Spark Job")
                .setMaster("local[*]");

        // Create a JavaSparkContext
        JavaSparkContext sc = new JavaSparkContext(conf);

        // Perform some Spark actions
        // For example, read a CSV file and count the number of rows
        long count = sc.textFile("input.csv").count();

        // Print the result
        System.out.println("Number of rows: " + count);

        // Stop the Spark context
        sc.stop();
    }
}


spark-submit --class com.example.MyApplication \
    --master yarn \
    --deploy-mode client \
    my-application.jar

